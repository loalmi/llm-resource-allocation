{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"13Z323N2uVbkqQzoI8qWmCBliHWE942I8","authorship_tag":"ABX9TyNW0MF4G2+twLOaBx6fERbT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# https://github.com/loalmi/llm-resource-allocation.git"],"metadata":{"id":"tJgoo6O4rZlo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.name \"@loalm\"\n","!git config --global user.email \"loalmi35@gmail.com\""],"metadata":{"id":"Lwq7-5Czrgnk","executionInfo":{"status":"ok","timestamp":1769035105948,"user_tz":-180,"elapsed":298,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/loalmi/llm-resource-allocation.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9AnkGHYsC4X","executionInfo":{"status":"ok","timestamp":1769035107175,"user_tz":-180,"elapsed":210,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"59dbc0cf-ed58-4486-d9c3-b878440457c2"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'llm-resource-allocation'...\n","remote: Enumerating objects: 6, done.\u001b[K\n","remote: Counting objects:  16% (1/6)\u001b[K\rremote: Counting objects:  33% (2/6)\u001b[K\rremote: Counting objects:  50% (3/6)\u001b[K\rremote: Counting objects:  66% (4/6)\u001b[K\rremote: Counting objects:  83% (5/6)\u001b[K\rremote: Counting objects: 100% (6/6)\u001b[K\rremote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects:  25% (1/4)\u001b[K\rremote: Compressing objects:  50% (2/4)\u001b[K\rremote: Compressing objects:  75% (3/4)\u001b[K\rremote: Compressing objects: 100% (4/4)\u001b[K\rremote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects:  16% (1/6)\rReceiving objects:  33% (2/6)\rReceiving objects:  50% (3/6)\rReceiving objects:  66% (4/6)\rReceiving objects:  83% (5/6)\rReceiving objects: 100% (6/6)\rReceiving objects: 100% (6/6), done.\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2chbj06xt7CU","executionInfo":{"status":"ok","timestamp":1769035248824,"user_tz":-180,"elapsed":122,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"26604af6-4dcb-4f8f-9688-174a4f76bb32"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["bin\t datalab  home\t  lib32   media  proc\t\t    root  srv  tools\n","boot\t dev\t  kaggle  lib64   mnt\t python-apt\t    run   sys  usr\n","content  etc\t  lib\t  libx32  opt\t python-apt.tar.xz  sbin  tmp  var\n"]}]},{"cell_type":"code","source":["%cd content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1wAWqWLt_Mk","executionInfo":{"status":"ok","timestamp":1769035555202,"user_tz":-180,"elapsed":15,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"c71b23e5-c32e-442d-8000-871469429ae8"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OM_am0XZuEPH","executionInfo":{"status":"ok","timestamp":1769035556195,"user_tz":-180,"elapsed":128,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"670be6ae-becf-44b7-ce7d-88aee98470b0"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["llm-resource-allocation\t\t      openrouter_test_20260121_221140.json\n","openrouter_test_20260121_212158.json  openrouter_test_20260121_221951.json\n","openrouter_test_20260121_214138.json  results_GAIA_123.json\n","openrouter_test_20260121_214902.json  sample_data\n"]}]},{"cell_type":"code","source":["%cd llm-resource-allocation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s0MIR0QLsXJu","executionInfo":{"status":"ok","timestamp":1769035559498,"user_tz":-180,"elapsed":21,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"f8900825-72ef-47ee-8a4c-1bbefe061756"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/llm-resource-allocation\n"]}]},{"cell_type":"code","source":["# !rm -rf llm-resource-allocation"],"metadata":{"id":"H7Zc9O90vaB_","executionInfo":{"status":"ok","timestamp":1769035639179,"user_tz":-180,"elapsed":123,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ti5jFdhtcn4","executionInfo":{"status":"ok","timestamp":1769036205427,"user_tz":-180,"elapsed":99,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"e86604de-6134-417b-ee55-8275e3ef02c5"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["experiments  README.md\n"]}]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/МАГА 1 курс/НИР/llm-resource-allocation_.ipynb\" ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YxvaDuuNtib-","executionInfo":{"status":"ok","timestamp":1769036310190,"user_tz":-180,"elapsed":110,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"4b0552af-1606-4112-b70f-ca4e3a9e200f"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/drive/MyDrive/МАГА 1 курс/НИР/llm-resource-allocation_.ipynb': No such file or directory\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_UfJnC1v9fq","executionInfo":{"status":"ok","timestamp":1769036229274,"user_tz":-180,"elapsed":189,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"4037bebf-0374-40d8-a426-017fe12076aa"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["experiments  README.md\n"]}]},{"cell_type":"code","source":["!git add llm-resource-allocation_.ipynb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zhpSIuNxuK-","executionInfo":{"status":"ok","timestamp":1769036245903,"user_tz":-180,"elapsed":202,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"944d1bdb-1e18-4106-be27-de4ef7e61045"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: pathspec 'llm-resource-allocation_.ipynb' did not match any files\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hukn0xaJs94p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I3BvyzTJs98D"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"id":"WLbociFanOb2","executionInfo":{"status":"ok","timestamp":1769030489436,"user_tz":-180,"elapsed":7,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"a5fe4587-f4c3-4e7f-8431-5f23e78de1fc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nМультиагентная система для решения задач GAIA с game-theoretic распределением ресурсов\\nАрхитектура: GAIA задача → Декомпозитор → Подзадачи → Оракул → Роутер → Агенты\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}],"source":["\"\"\"\n","Мультиагентная система для решения задач GAIA с game-theoretic распределением ресурсов\n","Архитектура: GAIA задача → Декомпозитор → Подзадачи → Оракул → Роутер → Агенты\n","\"\"\""]},{"cell_type":"code","source":["import numpy as np\n","from typing import List, Dict, Tuple, Optional\n","from dataclasses import dataclass\n","import json\n","from enum import Enum"],"metadata":{"id":"aPNd_XDEnZXw","executionInfo":{"status":"ok","timestamp":1769030489437,"user_tz":-180,"elapsed":3,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["Структура данных:\n","\n","    - Subtask: Подзадача с типом и порядковым номером\n","    - Agent: Агент с ролью и инструментами\n","    - ModelPackage: Модель + токены равной стоимости\n","    - Allocation: Распределение (подзадача → агент → модель)\n","\n","Основные компоненты:\n","\n","    - TaskDecomposer: Анализирует колонку GAIA, классифицирует типы подзадач\n","    - UtilityOracle: Генерирует 3D матрицу полезностей\n","    - GameTheoreticRouter: Распределяет с учетом fairness критериев\n","    - BaseAgent: Исполняет подзадачи с поддержкой контекста"],"metadata":{"id":"cwsGePgYpOXM"}},{"cell_type":"markdown","source":["**Модели данных**"],"metadata":{"id":"1CzCGQosyvyY"}},{"cell_type":"code","source":["class TaskType(Enum):\n","    RESEARCH = \"research\"\n","    ANALYSIS = \"analysis\"\n","    CODING = \"coding\"\n","    REASONING = \"reasoning\"\n","    SUMMARIZATION = \"summarization\"\n","\n","class AgentRole(Enum):\n","    RESEARCHER = \"researcher\"\n","    ANALYST = \"analyst\"\n","    PROGRAMMER = \"programmer\"\n","    REASONER = \"reasoner\"\n","    WRITER = \"writer\"\n","\n","class LLMModel(Enum):\n","    GPT4 = \"gpt-4\"\n","    CLAUDE3 = \"claude-3\"\n","    LLAMA3 = \"llama-3\"\n","    GEMMA = \"gemma\"\n","    MIXTRAL = \"mixtral\"\n","\n","@dataclass\n","class Subtask:\n","    \"\"\"Подзадача после декомпозиции\"\"\"\n","    id: str\n","    description: str\n","    task_type: TaskType\n","    parent_task_id: str\n","    step_number: int\n","\n","@dataclass\n","class Agent:\n","    \"\"\"Агент с ролью и конфигурацией\"\"\"\n","    id: str\n","    role: AgentRole\n","    tools: List[str]  # Инструменты агента\n","    memory_size: int = 1000\n","\n","@dataclass\n","class ModelPackage:\n","    \"\"\"Пакет: модель + количество токенов (равной стоимости)\"\"\"\n","    model: LLMModel\n","    token_budget: int\n","    cost: float  # Все пакеты имеют одинаковую стоимость\n","\n","@dataclass\n","class Allocation:\n","    \"\"\"Распределение подзадачи агенту с моделью\"\"\"\n","    subtask: Subtask\n","    agent: Agent\n","    model_package: ModelPackage\n","    predicted_utility: float\n"],"metadata":{"id":"0ufQp1c6ytsu","executionInfo":{"status":"ok","timestamp":1769030489439,"user_tz":-180,"elapsed":1,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["**Декомпозитор**"],"metadata":{"id":"M4zlsnzyy2qa"}},{"cell_type":"code","source":["class TaskDecomposer:\n","    \"\"\"Разбивает задачи GAIA на последовательные подзадачи\"\"\"\n","\n","    def __init__(self):\n","        self.cache = {}  # Кэш декомпозиций\n","\n","    def decompose_gaia_task(self, task_id: str, task_description: str,\n","                          subtasks_column: List[str]) -> List[Subtask]:\n","        \"\"\"\n","        Преобразует колонку с подзадачами из GAIA в структурированные Subtask объекты\n","\n","        Args:\n","            task_id: ID задачи из GAIA\n","            task_description: Описание основной задачи\n","            subtasks_column: Список шагов из колонки GAIA (аннотированные человеком)\n","\n","        Returns:\n","            Список подзадач с типами и порядковыми номерами\n","        \"\"\"\n","        if task_id in self.cache:\n","            return self.cache[task_id]\n","\n","        subtasks = []\n","        for i, step in enumerate(subtasks_column, 1):\n","            # Определяем тип задачи на основе содержимого\n","            task_type = self._classify_subtask(step)\n","\n","            subtask = Subtask(\n","                id=f\"{task_id}_step_{i}\",\n","                description=step,\n","                task_type=task_type,\n","                parent_task_id=task_id,\n","                step_number=i\n","            )\n","            subtasks.append(subtask)\n","\n","        self.cache[task_id] = subtasks\n","        return subtasks\n","\n","    def _classify_subtask(self, step_description: str) -> TaskType:\n","        \"\"\"Классифицирует тип подзадачи по описанию\"\"\"\n","        step_lower = step_description.lower()\n","\n","        if any(word in step_lower for word in [\"find\", \"search\", \"look up\", \"gather\"]):\n","            return TaskType.RESEARCH\n","        elif any(word in step_lower for word in [\"analyze\", \"compare\", \"calculate\", \"evaluate\"]):\n","            return TaskType.ANALYSIS\n","        elif any(word in step_lower for word in [\"code\", \"program\", \"implement\", \"function\"]):\n","            return TaskType.CODING\n","        elif any(word in step_lower for word in [\"reason\", \"deduce\", \"infer\", \"if-then\"]):\n","            return TaskType.REASONING\n","        elif any(word in step_lower for word in [\"summarize\", \"conclude\", \"write\", \"report\"]):\n","            return TaskType.SUMMARIZATION\n","        else:\n","            return TaskType.ANALYSIS  # По умолчанию"],"metadata":{"id":"0iI6QK5-y23a","executionInfo":{"status":"ok","timestamp":1769030489485,"user_tz":-180,"elapsed":45,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["**Оракул (генерация кубика полезности)**"],"metadata":{"id":"mL8Wun71zCe1"}},{"cell_type":"code","source":["class UtilityOracle:\n","    \"\"\"Генерирует кубик оценок U[subtask][agent][model]\"\"\"\n","\n","    def __init__(self, temperature: float = 0.1):\n","        self.temperature = temperature\n","        self.utility_cubes = {}  # Кэш кубиков по task_id\n","\n","    def generate_utility_cube(self, subtasks: List[Subtask],\n","                            agents: List[Agent],\n","                            model_packages: List[ModelPackage]) -> np.ndarray:\n","        \"\"\"\n","        Генерирует 3D матрицу полезностей U[subtask][agent][model]\n","\n","        Returns:\n","            numpy array shape (n_subtasks, n_agents, n_models)\n","        \"\"\"\n","        task_id = subtasks[0].parent_task_id if subtasks else \"unknown\"\n","\n","        if task_id in self.utility_cubes:\n","            return self.utility_cubes[task_id]\n","\n","        n_subtasks = len(subtasks)\n","        n_agents = len(agents)\n","        n_models = len(model_packages)\n","\n","        utility_cube = np.zeros((n_subtasks, n_agents, n_models))\n","\n","        # Генерация оценок (пока заглушка - в реальности через LLM)\n","        for i, subtask in enumerate(subtasks):\n","            for j, agent in enumerate(agents):\n","                for k, model_pkg in enumerate(model_packages):\n","                    utility_cube[i, j, k] = self._estimate_utility(\n","                        subtask, agent, model_pkg\n","                    )\n","\n","        self.utility_cubes[task_id] = utility_cube\n","        return utility_cube\n","\n","    def _estimate_utility(self, subtask: Subtask, agent: Agent,\n","                         model_pkg: ModelPackage) -> float:\n","        \"\"\"\n","        Оценивает полезность комбинации (заглушка - будет заменена на LLM вызов)\n","\n","        В реальности:\n","        1. Формируем промпт: \"Насколько хорошо {agent.role} с {model}\n","           решит задачу: {subtask.description}? Оцени 0-1\"\n","        2. Вызываем LLM\n","        3. Парсим ответ\n","        \"\"\"\n","        # Базовая эвристика\n","        base_score = 0.5\n","\n","        # Корректировка по специализации агента\n","        role_fit = self._get_role_fit_score(subtask.task_type, agent.role)\n","        base_score *= role_fit\n","\n","        # Корректировка по модели\n","        model_fit = self._get_model_fit_score(subtask.task_type, model_pkg.model)\n","        base_score *= model_fit\n","\n","        # Добавляем небольшой шум\n","        noise = np.random.normal(0, 0.1 * self.temperature)\n","        return np.clip(base_score + noise, 0.0, 1.0)\n","\n","    def _get_role_fit_score(self, task_type: TaskType, agent_role: AgentRole) -> float:\n","        \"\"\"Сколько агент подходит для типа задачи\"\"\"\n","        fit_matrix = {\n","            TaskType.RESEARCH: {\n","                AgentRole.RESEARCHER: 0.9,\n","                AgentRole.ANALYST: 0.7,\n","                AgentRole.REASONER: 0.6,\n","                AgentRole.PROGRAMMER: 0.3,\n","                AgentRole.WRITER: 0.4,\n","            },\n","            TaskType.ANALYSIS: {\n","                AgentRole.RESEARCHER: 0.6,\n","                AgentRole.ANALYST: 0.9,\n","                AgentRole.REASONER: 0.8,\n","                AgentRole.PROGRAMMER: 0.5,\n","                AgentRole.WRITER: 0.4,\n","            },\n","            # ... аналогично для других типов\n","        }\n","        return fit_matrix.get(task_type, {}).get(agent_role, 0.5)\n","\n","    def _get_model_fit_score(self, task_type: TaskType, model: LLMModel) -> float:\n","        \"\"\"Насколько модель подходит для типа задачи\"\"\"\n","        # Упрощенная матрица\n","        return 0.8  # Заглушка"],"metadata":{"id":"BMCZw8b5y-7I","executionInfo":{"status":"ok","timestamp":1769030489487,"user_tz":-180,"elapsed":1,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["**Роутер (распределение моделей по агентам)**"],"metadata":{"id":"KlF3W_jxzLVR"}},{"cell_type":"code","source":["class GameTheoreticRouter:\n","    \"\"\"Распределяет подзадачи по агентам на основе кубика оценок\"\"\"\n","\n","    def __init__(self, fairness_criterion: str = \"NSW\"):\n","        \"\"\"\n","        Args:\n","            fairness_criterion: \"NSW\" (Nash), \"USW\" (Utilitarian), \"EF\" (Envy-Free)\n","        \"\"\"\n","        self.fairness_criterion = fairness_criterion\n","\n","    def allocate_tasks(self, subtasks: List[Subtask],\n","                      agents: List[Agent],\n","                      model_packages: List[ModelPackage],\n","                      utility_cube: np.ndarray) -> List[Allocation]:\n","        \"\"\"\n","        Распределяет подзадачи с учетом последовательности выполнения\n","\n","        Особенность: Каждая следующая подзадача получает результаты предыдущей\n","        \"\"\"\n","        n_subtasks = len(subtasks)\n","        n_agents = len(agents)\n","\n","        allocations = []\n","        previous_results = None\n","\n","        for step in range(n_subtasks):\n","            # Для последовательных задач учитываем предыдущие результаты\n","            context_aware_utility = self._adjust_utilities_for_context(\n","                utility_cube[step], previous_results, step\n","            )\n","\n","            # Выбираем оптимальное распределение для текущего шага\n","            allocation = self._allocate_single_step(\n","                subtasks[step], agents, model_packages, context_aware_utility, step\n","            )\n","\n","            allocations.append(allocation)\n","\n","            # Обновляем контекст для следующего шага\n","            previous_results = {\n","                'step': step,\n","                'agent': allocation.agent,\n","                'model': allocation.model_package.model,\n","                'subtask_type': subtasks[step].task_type\n","            }\n","\n","        return allocations\n","\n","    def _allocate_single_step(self, subtask: Subtask,\n","                            agents: List[Agent],\n","                            model_packages: List[ModelPackage],\n","                            utilities_2d: np.ndarray,  # [agent][model]\n","                            step_number: int) -> Allocation:\n","        \"\"\"Распределяет одну подзадачу\"\"\"\n","\n","        if self.fairness_criterion == \"USW\":\n","            # Утилитарный подход: максимизация суммы\n","            best_agent_idx, best_model_idx = np.unravel_index(\n","                np.argmax(utilities_2d), utilities_2d.shape\n","            )\n","\n","        elif self.fairness_criterion == \"NSW\":\n","            # Nash Social Welfare (баланс efficiency/fairness)\n","            # Пока упрощенная версия\n","            best_agent_idx, best_model_idx = self._nash_allocation(utilities_2d, step_number)\n","\n","        elif self.fairness_criterion == \"EF\":\n","            # Envy-Free распределение\n","            best_agent_idx, best_model_idx = self._envy_free_allocation(utilities_2d, step_number)\n","\n","        else:\n","            raise ValueError(f\"Unknown fairness criterion: {self.fairness_criterion}\")\n","\n","        return Allocation(\n","            subtask=subtask,\n","            agent=agents[best_agent_idx],\n","            model_package=model_packages[best_model_idx],\n","            predicted_utility=utilities_2d[best_agent_idx, best_model_idx]\n","        )\n","\n","    def _adjust_utilities_for_context(self, utilities_2d: np.ndarray,\n","                                    previous_results: Optional[Dict],\n","                                    current_step: int) -> np.ndarray:\n","        \"\"\"Корректирует полезности с учетом контекста (результатов предыдущих шагов)\"\"\"\n","        adjusted = utilities_2d.copy()\n","\n","        if previous_results is not None:\n","            # Пример эвристики: агент, который уже работал, может быть более эффективен\n","            # на связанных задачах\n","            # В реальности это будет определяться через LLM анализ связанности задач\n","            pass\n","\n","        return adjusted\n","\n","    def _nash_allocation(self, utilities_2d: np.ndarray, step: int) -> Tuple[int, int]:\n","        \"\"\"Упрощенная версия NSW распределения\"\"\"\n","        # Пока используем жадный подход с учетом предыдущих назначений\n","        # В полной версии будем оптимизировать произведение полезностей\n","        return np.unravel_index(np.argmax(utilities_2d), utilities_2d.shape)\n","\n","    def _envy_free_allocation(self, utilities_2d: np.ndarray, step: int) -> Tuple[int, int]:\n","        \"\"\"Упрощенная версия EF распределения\"\"\"\n","        # Пока аналогично NSW\n","        return np.unravel_index(np.argmax(utilities_2d), utilities_2d.shape)\n"],"metadata":{"id":"11GYHwgyzLmc","executionInfo":{"status":"ok","timestamp":1769030489521,"user_tz":-180,"elapsed":33,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["**Агенты (исполнители)**"],"metadata":{"id":"wh5vrsoPzVCe"}},{"cell_type":"code","source":["class BaseAgent:\n","    \"\"\"Базовый класс агента\"\"\"\n","\n","    def __init__(self, agent_id: str, role: AgentRole):\n","        self.id = agent_id\n","        self.role = role\n","        self.memory = []\n","\n","    def execute(self, subtask: Subtask, model_package: ModelPackage,\n","                context: Optional[str] = None) -> str:\n","        \"\"\"\n","        Выполняет подзадачу с заданной моделью\n","\n","        Args:\n","            subtask: Подзадача для выполнения\n","            model_package: Модель и бюджет токенов\n","            context: Результаты предыдущих шагов (для последовательных задач)\n","\n","        Returns:\n","            Результат выполнения\n","        \"\"\"\n","        # Формируем промпт с учетом контекста\n","        prompt = self._build_prompt(subtask, context)\n","\n","        # Вызываем LLM (заглушка)\n","        result = self._call_llm(prompt, model_package)\n","\n","        # Сохраняем в память\n","        self.memory.append({\n","            'subtask': subtask.id,\n","            'prompt': prompt[:100],  # Сохраняем начало для отладки\n","            'result': result[:500],  # Сохраняем начало результата\n","            'model': model_package.model.value\n","        })\n","\n","        return result\n","\n","    def _build_prompt(self, subtask: Subtask, context: Optional[str]) -> str:\n","        \"\"\"Формирует промпт для LLM\"\"\"\n","        prompt = f\"\"\"\n","        Ты {self.role.value} в мультиагентной системе.\n","\n","        Задача: {subtask.description}\n","        \"\"\"\n","\n","        if context:\n","            prompt += f\"\\nКонтекст (результаты предыдущих шагов):\\n{context}\"\n","\n","        prompt += f\"\\n\\nВыполни эту задачу шаг за шагом. Будь точным и детальным.\"\n","\n","        return prompt\n","\n","    def _call_llm(self, prompt: str, model_package: ModelPackage) -> str:\n","        \"\"\"Заглушка для вызова LLM\"\"\"\n","        # В реальности: вызов API соответствующей модели\n","        return f\"Результат выполнения задачи с моделью {model_package.model.value}\"\n"],"metadata":{"id":"ORHTNX--zVQy","executionInfo":{"status":"ok","timestamp":1769030489582,"user_tz":-180,"elapsed":20,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["**Главная система - координация остальных компонент (архитектура, которая описывалась первоначально)**"],"metadata":{"id":"rtm8xoPWzgh9"}},{"cell_type":"code","source":["class MultiAgentSystem:\n","    \"\"\"Основная система, координирующая все компоненты\"\"\"\n","\n","    def __init__(self):\n","        self.decomposer = TaskDecomposer()\n","        self.oracle = UtilityOracle()\n","        self.router = GameTheoreticRouter(fairness_criterion=\"NSW\")\n","        self.agents = self._initialize_agents()\n","        self.model_packages = self._initialize_model_packages()\n","\n","    def _initialize_agents(self) -> List[Agent]:\n","        \"\"\"Инициализирует агентов с разными ролями\"\"\"\n","        return [\n","            Agent(id=\"agent_1\", role=AgentRole.RESEARCHER, tools=[\"web_search\", \"data_collection\"]),\n","            Agent(id=\"agent_2\", role=AgentRole.ANALYST, tools=[\"statistics\", \"data_analysis\"]),\n","            Agent(id=\"agent_3\", role=AgentRole.PROGRAMMER, tools=[\"code_generation\", \"debugging\"]),\n","            Agent(id=\"agent_4\", role=AgentRole.REASONER, tools=[\"logical_reasoning\", \"inference\"]),\n","            Agent(id=\"agent_5\", role=AgentRole.WRITER, tools=[\"summarization\", \"report_writing\"]),\n","        ]\n","\n","    def _initialize_model_packages(self) -> List[ModelPackage]:\n","        \"\"\"Создает пакеты моделей с токенами равной стоимости\"\"\"\n","        # Все пакеты имеют одинаковую стоимость (например, $0.10)\n","        base_cost = 0.10\n","\n","        return [\n","            ModelPackage(model=LLMModel.GPT4, token_budget=1000, cost=base_cost),\n","            ModelPackage(model=LLMModel.CLAUDE3, token_budget=1500, cost=base_cost),\n","            ModelPackage(model=LLMModel.LLAMA3, token_budget=3000, cost=base_cost),\n","            ModelPackage(model=LLMModel.GEMMA, token_budget=3500, cost=base_cost),\n","            ModelPackage(model=LLMModel.MIXTRAL, token_budget=2500, cost=base_cost),\n","        ]\n","\n","    def solve_gaia_task(self, task_id: str, task_description: str,\n","                       gaia_subtasks: List[str]) -> Dict:\n","        \"\"\"\n","        Основной пайплайн решения задачи GAIA\n","\n","        Args:\n","            task_id: ID задачи из GAIA\n","            task_description: Описание задачи\n","            gaia_subtasks: Список подзадач из колонки GAIA\n","\n","        Returns:\n","            Результаты выполнения\n","        \"\"\"\n","        print(f\"Начинаем решение задачи {task_id}\")\n","\n","        print(\"1. Декомпозиция задачи...\")\n","        subtasks = self.decomposer.decompose_gaia_task(\n","            task_id, task_description, gaia_subtasks\n","        )\n","        print(f\"   Получено {len(subtasks)} подзадач\")\n","\n","        print(\"2. Генерация кубика оценок...\")\n","        utility_cube = self.oracle.generate_utility_cube(\n","            subtasks, self.agents, self.model_packages\n","        )\n","        print(f\"   Размер кубика: {utility_cube.shape}\")\n","\n","        print(\"3. Распределение подзадач (роутинг)...\")\n","        allocations = self.router.allocate_tasks(\n","            subtasks, self.agents, self.model_packages, utility_cube\n","        )\n","\n","        print(\"4. Последовательное выполнение подзадач...\")\n","        results = []\n","        previous_result = None\n","\n","        for i, allocation in enumerate(allocations):\n","            print(f\"   Шаг {i+1}: {allocation.agent.role.value} → {allocation.model_package.model.value}\")\n","\n","            # Создаем экземпляр агента\n","            agent_instance = BaseAgent(allocation.agent.id, allocation.agent.role)\n","\n","            # Выполняем с учетом предыдущих результатов\n","            result = agent_instance.execute(\n","                allocation.subtask,\n","                allocation.model_package,\n","                context=previous_result\n","            )\n","\n","            results.append({\n","                'step': i + 1,\n","                'subtask': allocation.subtask.description,\n","                'agent': allocation.agent.role.value,\n","                'model': allocation.model_package.model.value,\n","                'predicted_utility': allocation.predicted_utility,\n","                'result': result[:200]  # Сохраняем начало\n","            })\n","\n","            # Обновляем контекст для следующего шага\n","            previous_result = result\n","\n","        # 5. Агрегация результатов\n","        print(\"5. Агрегация финального ответа...\")\n","        final_answer = self._aggregate_results(results)\n","\n","        return {\n","            'task_id': task_id,\n","            'allocations': [\n","                {\n","                    'step': r['step'],\n","                    'agent': r['agent'],\n","                    'model': r['model'],\n","                    'utility': r['predicted_utility']\n","                } for r in results\n","            ],\n","            'final_answer': final_answer,\n","            'utility_cube_stats': {\n","                'mean': float(np.mean(utility_cube)),\n","                'std': float(np.std(utility_cube)),\n","                'max': float(np.max(utility_cube)),\n","                'min': float(np.min(utility_cube))\n","            }\n","        }\n","\n","    def _aggregate_results(self, results: List[Dict]) -> str:\n","        \"\"\"Агрегирует результаты всех шагов в финальный ответ\"\"\"\n","        # В реальности может быть отдельный агент-агрегатор\n","        aggregated = \"Финальный ответ на задачу:\\n\\n\"\n","        for r in results:\n","            aggregated += f\"Шаг {r['step']} ({r['agent']}): {r['result']}\\n\\n\"\n","        return aggregated"],"metadata":{"id":"eOxrmhXuzgv3","executionInfo":{"status":"ok","timestamp":1769030489603,"user_tz":-180,"elapsed":20,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["\n","\n","# ========== 7. ПРИМЕР ИСПОЛЬЗОВАНИЯ ==========\n","\n","def main():\n","    \"\"\"Пример использования системы с тестовой задачей GAIA\"\"\"\n","\n","    # Создаем систему\n","    mas = MultiAgentSystem()\n","\n","    # Тестовая задача GAIA (пример)\n","    task_id = \"GAIA_123\"\n","    task_description = \"Проанализируйте влияние изменения налоговой политики на малый бизнес\"\n","\n","    # Подзадачи из колонки GAIA (аннотированные человеком)\n","    gaia_subtasks = [\n","        \"Найти данные по налоговой нагрузке на малый бизнес за последние 5 лет\",\n","        \"Проанализировать корреляцию между изменением налогов и количеством банкротств\",\n","        \"Рассчитать экономический эффект от предлагаемых изменений\",\n","        \"Сформулировать выводы и рекомендации для правительства\"\n","    ]\n","\n","    # Запускаем систему\n","    try:\n","        result = mas.solve_gaia_task(task_id, task_description, gaia_subtasks)\n","\n","        # Выводим результаты\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"РЕЗУЛЬТАТЫ ВЫПОЛНЕНИЯ\")\n","\n","        print(f\"\\nЗадача: {task_id}\")\n","        print(f\"Распределение подзадач:\")\n","        for alloc in result['allocations']:\n","            print(f\"  Шаг {alloc['step']}: {alloc['agent']} + {alloc['model']} (utility: {alloc['utility']:.2f})\")\n","\n","        print(f\"\\nСтатистика кубика оценок:\")\n","        stats = result['utility_cube_stats']\n","        print(f\"  Среднее: {stats['mean']:.3f}, Std: {stats['std']:.3f}\")\n","        print(f\"  Min: {stats['min']:.3f}, Max: {stats['max']:.3f}\")\n","\n","        print(f\"\\nФинальный ответ (первые 500 символов):\")\n","        print(result['final_answer'][:500] + \"...\")\n","\n","        # Сохраняем результаты\n","        with open(f\"results_{task_id}.json\", \"w\", encoding=\"utf-8\") as f:\n","            json.dump(result, f, indent=2, ensure_ascii=False)\n","        print(f\"\\nРезультаты сохранены в results_{task_id}.json\")\n","\n","    except Exception as e:\n","        print(f\"Ошибка: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJ4QVpmcnbWD","executionInfo":{"status":"ok","timestamp":1769030489682,"user_tz":-180,"elapsed":78,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"a30cca45-5c3b-45d7-894a-68847aeb81ef"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Начинаем решение задачи GAIA_123\n","1. Декомпозиция задачи...\n","   Получено 4 подзадач\n","2. Генерация кубика оценок...\n","   Размер кубика: (4, 5, 5)\n","3. Распределение подзадач (роутинг)...\n","4. Последовательное выполнение подзадач...\n","   Шаг 1: analyst → claude-3\n","   Шаг 2: analyst → gemma\n","   Шаг 3: analyst → claude-3\n","   Шаг 4: analyst → gemma\n","5. Агрегация финального ответа...\n","\n","============================================================\n","РЕЗУЛЬТАТЫ ВЫПОЛНЕНИЯ\n","\n","Задача: GAIA_123\n","Распределение подзадач:\n","  Шаг 1: analyst + claude-3 (utility: 0.37)\n","  Шаг 2: analyst + gemma (utility: 0.37)\n","  Шаг 3: analyst + claude-3 (utility: 0.37)\n","  Шаг 4: analyst + gemma (utility: 0.37)\n","\n","Статистика кубика оценок:\n","  Среднее: 0.257, Std: 0.074\n","  Min: 0.147, Max: 0.375\n","\n","Финальный ответ (первые 500 символов):\n","Финальный ответ на задачу:\n","\n","Шаг 1 (analyst): Результат выполнения задачи с моделью claude-3\n","\n","Шаг 2 (analyst): Результат выполнения задачи с моделью gemma\n","\n","Шаг 3 (analyst): Результат выполнения задачи с моделью claude-3\n","\n","Шаг 4 (analyst): Результат выполнения задачи с моделью gemma\n","\n","...\n","\n","Результаты сохранены в results_GAIA_123.json\n"]}]},{"cell_type":"markdown","source":["## **Настройка OpenRouter**"],"metadata":{"id":"aBb3FVAwVvmH"}},{"cell_type":"code","source":["pip install openai python-dotenv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EO8oM6qJVzUL","executionInfo":{"status":"ok","timestamp":1769030493970,"user_tz":-180,"elapsed":4287,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"b4324628-89d7-4c41-cf0c-1af8a11ce62d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.15.0)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n","Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","from typing import Dict, List, Optional, Any\n","from dataclasses import dataclass, asdict\n","from enum import Enum\n","import openai\n","from openai import OpenAI\n","from dotenv import load_dotenv\n","import numpy as np\n","from datetime import datetime"],"metadata":{"id":"QWxleqC6V78_","executionInfo":{"status":"ok","timestamp":1769030493985,"user_tz":-180,"elapsed":13,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Загружаем переменные окружения\n","load_dotenv()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUVsoVonWaES","executionInfo":{"status":"ok","timestamp":1769030494001,"user_tz":-180,"elapsed":14,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"e1e8f975-c06c-4902-8295-0877b85753d7"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["**Конфигурация и базовый класс**"],"metadata":{"id":"TdCFsi8JX2ak"}},{"cell_type":"code","source":["class ModelProvider(Enum):\n","    \"\"\"Провайдеры моделей через OpenRouter\"\"\"\n","    OPENROUTER = \"openrouter\"\n","\n","\n","@dataclass\n","class ModelConfig:\n","    \"\"\"Конфигурация одной модели\"\"\"\n","    name: str\n","    openrouter_id: str  # ID модели в OpenRouter\n","    context_window: int  # Максимальный контекст (в токенах)\n","    cost_per_1k_input: float  # Стоимость 1000 входных токенов ($)\n","    cost_per_1k_output: float  # Стоимость 1000 выходных токенов ($)\n","    description: str = \"\"  # Описание модели\n","\n","    def calculate_cost(self, input_tokens: int, output_tokens: int) -> float:\n","        \"\"\"Рассчитывает стоимость запроса\"\"\"\n","        input_cost = (input_tokens / 1000) * self.cost_per_1k_input\n","        output_cost = (output_tokens / 1000) * self.cost_per_1k_output\n","        return round(input_cost + output_cost, 4)\n","\n","class LLMModelInstance:\n","    \"\"\"Экземпляр модели LLM через OpenRouter\"\"\"\n","\n","    def __init__(self, config: ModelConfig, api_key: Optional[str] = None):\n","        self.config = config\n","        self.api_key = api_key or os.getenv(\"OPENROUTER_API_KEY\")\n","\n","        if not self.api_key:\n","            raise ValueError(\"OpenRouter API key не найден. Установите OPENROUTER_API_KEY в .env\")\n","\n","        # Инициализируем клиент OpenRouter\n","        self.client = OpenAI(\n","            base_url=\"https://openrouter.ai/api/v1\",\n","            api_key=self.api_key\n","        )\n","\n","        # Статистика использования\n","        self.total_tokens_used = 0\n","        self.total_cost = 0.0\n","        self.request_count = 0\n","\n","    def generate(self,\n","                 prompt: str,\n","                 system_prompt: Optional[str] = None,\n","                 max_tokens: int = 1000,\n","                 temperature: float = 0.7,\n","                 **kwargs) -> Dict[str, Any]:\n","        \"\"\"\n","        Генерирует ответ через OpenRouter\n","\n","        Args:\n","            prompt: Основной промпт\n","            system_prompt: Системный промпт (роль модели)\n","            max_tokens: Максимальное количество токенов в ответе\n","            temperature: Температура генерации (0-2)\n","\n","        Returns:\n","            Словарь с ответом и метаданными\n","        \"\"\"\n","        messages = []\n","\n","        # Добавляем системный промпт если есть\n","        if system_prompt:\n","            messages.append({\"role\": \"system\", \"content\": system_prompt})\n","\n","        # Добавляем пользовательский промпт\n","        messages.append({\"role\": \"user\", \"content\": prompt})\n","\n","        try:\n","            response = self.client.chat.completions.create(\n","                model=self.config.openrouter_id,\n","                messages=messages,\n","                max_tokens=max_tokens,\n","                temperature=temperature,\n","                **kwargs\n","            )\n","\n","            # Извлекаем ответ\n","            content = response.choices[0].message.content\n","\n","            # Собираем статистику\n","            usage = response.usage\n","            input_tokens = usage.prompt_tokens\n","            output_tokens = usage.completion_tokens\n","            total_tokens = usage.total_tokens\n","\n","            # Рассчитываем стоимость\n","            cost = self.config.calculate_cost(input_tokens, output_tokens)\n","\n","            # Обновляем статистику\n","            self.total_tokens_used += total_tokens\n","            self.total_cost += cost\n","            self.request_count += 1\n","\n","            return {\n","                \"content\": content,\n","                \"input_tokens\": input_tokens,\n","                \"output_tokens\": output_tokens,\n","                \"total_tokens\": total_tokens,\n","                \"cost\": cost,\n","                \"model\": self.config.name,\n","                \"finish_reason\": response.choices[0].finish_reason\n","            }\n","\n","        except Exception as e:\n","            print(f\"Ошибка при вызове {self.config.name}: {str(e)}\")\n","            return {\n","                \"content\": f\"ERROR: {str(e)}\",\n","                \"input_tokens\": 0,\n","                \"output_tokens\": 0,\n","                \"total_tokens\": 0,\n","                \"cost\": 0,\n","                \"model\": self.config.name,\n","                \"error\": str(e)\n","            }\n","\n","    def get_stats(self) -> Dict[str, Any]:\n","        \"\"\"Возвращает статистику использования модели\"\"\"\n","        return {\n","            \"model\": self.config.name,\n","            \"requests\": self.request_count,\n","            \"total_tokens\": self.total_tokens_used,\n","            \"total_cost\": round(self.total_cost, 4),\n","            \"avg_cost_per_request\": round(self.total_cost / self.request_count, 4) if self.request_count > 0 else 0\n","        }"],"metadata":{"id":"VL_zJvIkV09M","executionInfo":{"status":"ok","timestamp":1769030494018,"user_tz":-180,"elapsed":16,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["**Фабрика моделей**"],"metadata":{"id":"YoxGdqVGY7Ow"}},{"cell_type":"markdown","source":["Реальные расценки на OpenRouter"],"metadata":{"id":"63YkfiYLm-YZ"}},{"cell_type":"markdown","source":["*Meta: Llama 3 70B Instruct*\n","- *meta-llama/llama-3-70b-instruct*\n","\n","      Created Apr 18, 2024\n","      8,192 context\n","      $0.40/M input tokens\n","      $0.40/M output tokens\n","      получается :\n","      cost_per_1k_input=0.0004\n","      cost_per_1k_output=0.0004\n","\n","Meta: Llama 3 8B Instruct\n","- meta-llama/llama-3-8b-instruct\n","\n","      Created Apr 18, 2024\n","      8,192 context\n","      $0.03/M input tokens\n","      $0.06/M output tokens\n","      получается :\n","      cost_per_1k_input=0.00003\n","      cost_per_1k_output=0.00006\n","\n","Anthropic: Claude 3 Haiku\n","- anthropic/claude-3-haiku\n","\n","      Created Mar 13, 2024\n","      200,000 context\n","      $0.25/M input tokens\n","      $1.25/M output tokens\n","      получается :\n","      cost_per_1k_input=0.00025\n","      cost_per_1k_output=0.00125\n","\n","OpenAI: GPT-4o-mini\n","- openai/gpt-4o-mini\n","\n","      Created Jul 18, 2024\n","      128,000 context\n","      Starting at $0.15/M input tokens\n","      Starting at $0.60/M output tokens\n","      получается :\n","      cost_per_1k_input=0.00015\n","      cost_per_1k_output=0.0006\n","\n"],"metadata":{"id":"HfvbtE01lMfm"}},{"cell_type":"markdown","source":["**Создаем три конкретные модели**"],"metadata":{"id":"2LSAF1cNXwPO"}},{"cell_type":"code","source":["# Конфигурации для трех разных моделей через OpenRouter\n","MODEL_CONFIGS = {\n","    \"gpt4\": ModelConfig(\n","        name=\"GPT-4o-mini\",\n","        openrouter_id=\"openai/gpt-4o-mini\",\n","        context_window=8192,\n","        cost_per_1k_input=0.00015,   # Примерная стоимость\n","        cost_per_1k_output=0.0006,  # Примерная стоимость\n","        description=\"модель OpenAI, отлично подходит для сложных рассуждений\"\n","    ),\n","\n","    \"claude3\": ModelConfig(\n","        name=\"Claude-3 Haiku\",\n","        openrouter_id=\"anthropic/claude-3-haiku\",\n","        context_window=200000,\n","        cost_per_1k_input=0.00025,   # Примерная стоимость\n","        cost_per_1k_output=0.00125,  # Примерная стоимость\n","        description=\"Claude от Anthropic, хорош для анализа и рассуждений\"\n","    ),\n","\n","    # \"llama3\": ModelConfig(\n","    #     name=\"Llama-3 70B\",\n","    #     openrouter_id=\"meta-llama/llama-3-70b-instruct\",\n","    #     context_window=8192,\n","    #     cost_per_1k_input=0.0004,  # Примерная стоимость\n","    #     cost_per_1k_output=0.0004, # Примерная стоимость\n","    #     description=\"Мощная открытая модель от Meta, хорош для кодинга\"\n","    # )\n","\n","# Заменю модель, потому что предыдущ версия не всегда выдает ответ и требует специфичный ввод\n","      \"llama3\": ModelConfig(\n","        name=\"Llama-3 8B Instruct\",\n","        openrouter_id=\"meta-llama/llama-3-8b-instruct\",\n","        context_window=8192,\n","        cost_per_1k_input=0.00003,  # Примерная стоимость\n","        cost_per_1k_output=0.00006, # Примерная стоимость\n","        description=\"Мощная открытая модель от Meta, хорош для кодинга\"\n","    )\n","}\n","\n","class ModelFactory:\n","    \"\"\"Фабрика для создания экземпляров моделей\"\"\"\n","\n","    @staticmethod\n","    def create_model(model_key: str, api_key: Optional[str] = None) -> LLMModelInstance:\n","        \"\"\"Создает экземпляр модели по ключу\"\"\"\n","        if model_key not in MODEL_CONFIGS:\n","            available = list(MODEL_CONFIGS.keys())\n","            raise ValueError(f\"Модель {model_key} не найдена. Доступные: {available}\")\n","\n","        config = MODEL_CONFIGS[model_key]\n","        return LLMModelInstance(config, api_key)\n","\n","    @staticmethod\n","    def create_all_models(api_key: Optional[str] = None) -> Dict[str, LLMModelInstance]:\n","        \"\"\"Создает все три модели\"\"\"\n","        models = {}\n","        for key in MODEL_CONFIGS:\n","            models[key] = ModelFactory.create_model(key, api_key)\n","        return models"],"metadata":{"id":"oWvcMNScXr_4","executionInfo":{"status":"ok","timestamp":1769033975321,"user_tz":-180,"elapsed":38,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["**Интеграция с системой агентов**"],"metadata":{"id":"zGY4qLfGYZ0h"}},{"cell_type":"code","source":["class OpenRouterAgent:\n","    \"\"\"Агент, использующий модели через OpenRouter\"\"\"\n","\n","    def __init__(self,\n","                 agent_id: str,\n","                 role: str,\n","                 default_model_key: str = \"gpt4\",\n","                 api_key: Optional[str] = None):\n","\n","        self.agent_id = agent_id\n","        self.role = role\n","        self.api_key = api_key or os.getenv(\"OPENROUTER_API_KEY\")\n","\n","        # Создаем все три модели, которые может использовать агент\n","        self.models = ModelFactory.create_all_models(self.api_key)\n","        self.default_model = self.models[default_model_key]\n","\n","        # История запросов\n","        self.history = []\n","\n","    def execute_task(self,\n","                    task_description: str,\n","                    context: Optional[str] = None,\n","                    model_key: Optional[str] = None,\n","                    **kwargs) -> Dict[str, Any]:\n","        \"\"\"\n","        Выполняет задачу с выбранной моделью\n","\n","        Args:\n","            task_description: Описание задачи\n","            context: Контекст (результаты предыдущих шагов)\n","            model_key: Ключ модели (если None, используется default_model)\n","\n","        Returns:\n","            Результат выполнения\n","        \"\"\"\n","        # Выбираем модель\n","        model = self.models.get(model_key, self.default_model) if model_key else self.default_model\n","\n","        # Формируем системный промпт на основе роли агента\n","        system_prompt = self._create_system_prompt()\n","\n","        # Формируем полный промпт с контекстом\n","        full_prompt = self._create_full_prompt(task_description, context)\n","\n","        # Вызываем модель\n","        start_time = datetime.now()\n","        result = model.generate(\n","            prompt=full_prompt,\n","            system_prompt=system_prompt,\n","            **kwargs\n","        )\n","        end_time = datetime.now()\n","\n","        # Сохраняем в историю\n","        history_entry = {\n","            \"timestamp\": start_time.isoformat(),\n","            \"agent_id\": self.agent_id,\n","            \"role\": self.role,\n","            \"model\": model.config.name,\n","            \"task\": task_description,\n","            \"context\": context[:100] + \"...\" if context else None,\n","            \"response\": result[\"content\"][:500] + \"...\" if result[\"content\"] else \"\",\n","            \"tokens\": result[\"total_tokens\"],\n","            \"cost\": result[\"cost\"],\n","            \"duration_ms\": int((end_time - start_time).total_seconds() * 1000)\n","        }\n","        self.history.append(history_entry)\n","\n","        return {\n","            \"agent\": self.agent_id,\n","            \"role\": self.role,\n","            \"model\": model.config.name,\n","            \"response\": result[\"content\"],\n","            \"metadata\": result,\n","            \"history_entry\": history_entry\n","        }\n","\n","    def _create_system_prompt(self) -> str:\n","        \"\"\"Создает системный промпт на основе роли агента\"\"\"\n","        prompts = {\n","            \"researcher\": \"\"\"Ты эксперт-исследователь в мультиагентной системе.\n","Твоя задача: находить и анализировать информацию. Будь точным, приводи источники когда возможно.\n","Отвечай подробно, но по делу.\"\"\",\n","\n","            \"analyst\": \"\"\"Ты аналитик в мультиагентной системе.\n","Твоя задача: анализировать данные, находить закономерности, делать выводы.\n","Используй логические рассуждения, проверяй свои выводы.\"\"\",\n","\n","            \"programmer\": \"\"\"Ты программист в мультиагентной системе.\n","Твоя задача: писать код, решать технические проблемы, объяснять алгоритмы.\n","Пиши чистый, документированный код с примерами.\"\"\",\n","\n","            \"writer\": \"\"\"Ты писатель/суммаризатор в мультиагентной системе.\n","Твоя задача: структурировать информацию, писать отчеты, делать выводы.\n","Будь ясным, структурированным, избегай избыточности.\"\"\"\n","        }\n","\n","        return prompts.get(self.role, \"Ты полезный AI ассистент в мультиагентной системе.\")\n","\n","    def _create_full_prompt(self, task: str, context: Optional[str]) -> str:\n","        \"\"\"Создает полный промпт с контекстом\"\"\"\n","        if context:\n","            return f\"\"\"Контекст (результаты предыдущих шагов):\n","{context}\n","\n","Текущая задача:\n","{task}\n","\n","Выполни задачу, учитывая контекст выше.\"\"\"\n","        else:\n","            return task\n","\n","    def get_agent_stats(self) -> Dict[str, Any]:\n","        \"\"\"Статистика использования агента\"\"\"\n","        total_cost = sum(entry.get(\"cost\", 0) for entry in self.history)\n","        total_tokens = sum(entry.get(\"tokens\", 0) for entry in self.history)\n","\n","        # Статистика по моделям\n","        model_stats = {}\n","        for model_instance in self.models.values():\n","            model_stats[model_instance.config.name] = model_instance.get_stats()\n","\n","        return {\n","            \"agent_id\": self.agent_id,\n","            \"role\": self.role,\n","            \"total_requests\": len(self.history),\n","            \"total_tokens\": total_tokens,\n","            \"total_cost\": round(total_cost, 4),\n","            \"model_stats\": model_stats\n","        }"],"metadata":{"id":"ErdXcZRiYV9P","executionInfo":{"status":"ok","timestamp":1769033976486,"user_tz":-180,"elapsed":36,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["**Демонстрация работы системы**"],"metadata":{"id":"20pYrtphaUW3"}},{"cell_type":"code","source":["def demonstrate_openrouter_integration():\n","    \"\"\"Демонстрация использования OpenRouter с тремя моделями\"\"\"\n","\n","    print(\"Тест интеграции с OpenRouter API\")\n","\n","    # 1. Создаем агента-исследователя\n","    researcher = OpenRouterAgent(\n","        agent_id=\"researcher_1\",\n","        role=\"researcher\",\n","        default_model_key=\"gpt4\"\n","    )\n","\n","    # 2. Тестовая задача\n","    test_task = \"Найди информацию о применении теории игр в распределении ресурсов в мультиагентных системах. Дай краткий обзор.\"\n","\n","    print(\"\\nТестовая задача:\")\n","    print(f\"   {test_task}\")\n","\n","    # 3. Выполняем задачу с разными моделями\n","    print(\"\\nТестируем разные модели:\")\n","\n","    models_to_test = [\"gpt4\", \"claude3\", \"llama3\"]\n","\n","    for model_key in models_to_test:\n","        print(f\"\\n  - Модель: {MODEL_CONFIGS[model_key].name}\")\n","        print(f\"   {'─' * 40}\")\n","\n","        result = researcher.execute_task(\n","            task_description=test_task,\n","            model_key=model_key,\n","            max_tokens=300,\n","            temperature=0.7\n","        )\n","\n","        response = result[\"response\"]\n","        metadata = result[\"metadata\"]\n","\n","        print(f\"   Ответ (первые 200 символов):\")\n","        print(f\"   {response[:200]}...\")\n","        print(f\"   Токены: {metadata['total_tokens']} (in: {metadata['input_tokens']}, out: {metadata['output_tokens']})\")\n","        print(f\"   Стоимость: ${metadata['cost']}\")\n","\n","    # 4. Показываем статистику\n","    print(\"\\nСтатистика использования:\")\n","    stats = researcher.get_agent_stats()\n","\n","    for model_name, model_stat in stats[\"model_stats\"].items():\n","        print(f\"   {model_name}:\")\n","        print(f\"     Запросов: {model_stat['requests']}\")\n","        print(f\"     Токенов: {model_stat['total_tokens']}\")\n","        print(f\"     Стоимость: ${model_stat['total_cost']}\")\n","\n","    print(f\"\\n   Общая стоимость всех запросов: ${stats['total_cost']}\")\n","\n","    # 5. Сохраняем историю для анализа\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    filename = f\"openrouter_test_{timestamp}.json\"\n","\n","    with open(filename, \"w\", encoding=\"utf-8\") as f:\n","        json.dump({\n","            \"agent_stats\": stats,\n","            \"history\": researcher.history\n","        }, f, indent=2, ensure_ascii=False)\n","\n","    print(f\"\\n_История сохранена в {filename}\")\n","    print(\"\\n_Интеграция с OpenRouter готова к использованию!\")\n","\n","\n","\n","if __name__ == \"__main__\":\n","    # Проверка наличия API ключа\n","    if not os.getenv(\"OPENROUTER_API_KEY\"):\n","        print(\"OPENROUTER_API_KEY не найден в переменных окружения.\")\n","        print(\"   Создайте файл .env с содержимым:\")\n","        print(\"   OPENROUTER_API_KEY=sk-or-v1-...\")\n","        print('проверка гугл секретов__')\n","        if userdata.get('OPENROUTER_API_KEY'):\n","          from google.colab import userdata\n","          os.environ[\"OPENROUTER_API_KEY\"] = userdata.get('OPENROUTER_API_KEY')\n","          print('Всё ок, открыл из гугл секретов')\n","        else:\n","          print('Добавь ключ отдельно, не видит колаб')\n","    else:\n","        demonstrate_openrouter_integration()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0x1xKOZaU7b","executionInfo":{"status":"ok","timestamp":1769033991583,"user_tz":-180,"elapsed":13293,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"f56807a8-a6cf-40e0-b2a5-b098c2402a27"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Тест интеграции с OpenRouter API\n","\n","Тестовая задача:\n","   Найди информацию о применении теории игр в распределении ресурсов в мультиагентных системах. Дай краткий обзор.\n","\n","Тестируем разные модели:\n","\n","  - Модель: GPT-4o-mini\n","   ────────────────────────────────────────\n","   Ответ (первые 200 символов):\n","   Теория игр является мощным инструментом для анализа и оптимизации взаимодействий между агентами в мультиагентных системах (MAS). В контексте распределения ресурсов, она помогает моделировать конкурент...\n","   Токены: 388 (in: 88, out: 300)\n","   Стоимость: $0.0002\n","\n","  - Модель: Claude-3 Haiku\n","   ────────────────────────────────────────\n","   Ответ (первые 200 символов):\n","   Теория игр широко применяется в области распределения ресурсов в мультиагентных системах. Вот краткий обзор:\n","\n","1. Моделирование взаимодействия агентов:\n","Теория игр позволяет моделировать взаимодействие ...\n","   Токены: 423 (in: 123, out: 300)\n","   Стоимость: $0.0004\n","\n","  - Модель: Llama-3 8B Instruct\n","   ────────────────────────────────────────\n","   Ответ (первые 200 символов):\n","   Теория игр - это раздел математики, который изучает стратегии и решения, которые принимают участники, когда они взаимодействуют и принимают решения, исходя из своих интересов. В мультиагентных система...\n","   Токены: 414 (in: 114, out: 300)\n","   Стоимость: $0.0\n","\n","Статистика использования:\n","   GPT-4o-mini:\n","     Запросов: 1\n","     Токенов: 388\n","     Стоимость: $0.0002\n","   Claude-3 Haiku:\n","     Запросов: 1\n","     Токенов: 423\n","     Стоимость: $0.0004\n","   Llama-3 8B Instruct:\n","     Запросов: 1\n","     Токенов: 414\n","     Стоимость: $0.0\n","\n","   Общая стоимость всех запросов: $0.0006\n","\n","_История сохранена в openrouter_test_20260121_221951.json\n","\n","_Интеграция с OpenRouter готова к использованию!\n"]}]},{"cell_type":"code","source":["researcher = OpenRouterAgent(\n","    agent_id=\"researcher_1\",\n","    role=\"researcher\",\n","    default_model_key=\"gpt4\"\n",")\n","\n","test_task = \"Найди информацию о применении теории игр в распределении ресурсов в мультиагентных системах. Дай краткий обзор.\"\n","\n","print(\"\\nТестовая задача:\")\n","print(f\"   {test_task}\")\n","print(\"\\nТестируем разные модели:\")\n","models_to_test = [\"gpt4\", \"claude3\", \"llama3\"]\n","\n","model_key = models_to_test[-1]\n","print(f\"\\n  - Модель: {MODEL_CONFIGS[model_key].name}\")\n","print(f\"   {'─' * 40}\")\n","\n","result = researcher.execute_task(\n","    task_description=test_task,\n","    model_key=model_key,\n","    max_tokens=300,\n","    temperature=0.7\n",")\n","\n","response = result[\"response\"]\n","metadata = result[\"metadata\"]\n","\n","print(f\"   Ответ :\")\n","print(f\"   {response}...\")\n","print(f\"   Токены: {metadata['total_tokens']} (in: {metadata['input_tokens']}, out: {metadata['output_tokens']})\")\n","print(f\"   Стоимость: ${metadata['cost']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzq7MdW5jqws","executionInfo":{"status":"ok","timestamp":1769034029866,"user_tz":-180,"elapsed":4516,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"8bc1abfd-1903-4842-b681-88367f25bfb9"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Тестовая задача:\n","   Найди информацию о применении теории игр в распределении ресурсов в мультиагентных системах. Дай краткий обзор.\n","\n","Тестируем разные модели:\n","\n","  - Модель: Llama-3 8B Instruct\n","   ────────────────────────────────────────\n","   Ответ :\n","   The application of game theory in resource allocation in multi-agent systems is a widely researched topic. Here's a brief overview:\n","\n","**Introduction**\n","\n","Multi-agent systems (MAS) consist of multiple autonomous agents that interact with each other and their environment to achieve common or conflicting goals. Resource allocation is a critical problem in MAS, as agents need to coordinate to use shared resources efficiently. Game theory provides a mathematical framework for analyzing and solving such problems.\n","\n","**Applications of Game Theory in Resource Allocation**\n","\n","Game theory has been applied in various ways to solve resource allocation problems in MAS:\n","\n","1. **Nash Equilibrium**: The Nash equilibrium concept is used to analyze and predict the behavior of agents in a game. In resource allocation, Nash equilibrium is used to find a stable allocation of resources that is resistant to unilateral deviations by individual agents.\n","2. **Auctions**: Auctions are a common mechanism for allocating resources in MAS. Game theory is used to design auctions that maximize social welfare, efficiency, and fairness.\n","3. **Coalitional Games**: Coalitional games are used to model situations where agents form coalitions to achieve common goals. Game theory is used to analyze the stability and efficiency of these coalitions.\n","4. **Mechanism Design**: Mechanism design is the process of designing rules and protocols for resource allocation. Game theory is used to design mechanisms that are Pareto-optimal, fair, and efficient.\n","5. **Machine Learning**: Machine learning techniques, such as reinforcement learning and evolutionary algorithms, are used to solve...\n","   Токены: 413 (in: 113, out: 300)\n","   Стоимость: $0.0\n"]}]},{"cell_type":"markdown","source":["*проверка другого запроса*"],"metadata":{"id":"g-fc3OfKp0-T"}},{"cell_type":"code","source":["researcher = OpenRouterAgent(\n","    agent_id=\"researcher_1\",\n","    role=\"researcher\",\n","    default_model_key=\"gpt4\"\n",")\n","test_task = \"сделай очень кратний обзор методов машинного обучения. нужно уложиться в 300 токенов. можно меньше\"\n","\n","print(\"\\nТестовая задача:\")\n","print(f\"   {test_task}\")\n","print(\"\\nТестируем разные модели:\")\n","models_to_test = [\"gpt4\", \"claude3\", \"llama3\"]\n","\n","for model_key in models_to_test:\n","    print(f\"\\n  - Модель: {MODEL_CONFIGS[model_key].name}\")\n","    print(f\"   {'─' * 40}\")\n","\n","    result = researcher.execute_task(\n","        task_description=test_task,\n","        model_key=model_key,\n","        max_tokens=300,\n","        temperature=0.7\n","    )\n","\n","    response = result[\"response\"]\n","    metadata = result[\"metadata\"]\n","\n","    print(f\"   Ответ:\")\n","    print(f\"   {response}...\")\n","    print(f\"   Токены: {metadata['total_tokens']} (in: {metadata['input_tokens']}, out: {metadata['output_tokens']})\")\n","    print(f\"   Стоимость: ${metadata['cost']}\")\n","\n","# 4. Показываем статистику\n","print(\"\\nСтатистика использования:\")\n","stats = researcher.get_agent_stats()\n","\n","for model_name, model_stat in stats[\"model_stats\"].items():\n","    print(f\"   {model_name}:\")\n","    print(f\"     Запросов: {model_stat['requests']}\")\n","    print(f\"     Токенов: {model_stat['total_tokens']}\")\n","    print(f\"     Стоимость: ${model_stat['total_cost']}\")\n","\n","print(f\"\\n   Общая стоимость всех запросов: ${stats['total_cost']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmBd6tuqkV2I","executionInfo":{"status":"ok","timestamp":1769034308229,"user_tz":-180,"elapsed":13882,"user":{"displayName":"Лиса Алиса","userId":"10301218915678229551"}},"outputId":"a329db38-96ef-45bd-ed90-9e4608ee7d69"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Тестовая задача:\n","   сделай очень кратний обзор методов машинного обучения. нужно уложиться в 300 токенов. можно меньше\n","\n","Тестируем разные модели:\n","\n","  - Модель: GPT-4o-mini\n","   ────────────────────────────────────────\n","   Ответ:\n","   Методы машинного обучения делятся на три основные категории: \n","\n","1. **Обучение с учителем**: Модели обучаются на размеченных данных. Цель — предсказать выходные значения на основе входных. Примеры: линейная регрессия, деревья решений, нейронные сети. Используются в задачах классификации и регрессии.\n","\n","2. **Обучение без учителя**: Модели ищут скрытые паттерны в неразмеченных данных. Примеры: кластеризация (K-средние, иерархическая кластеризация), уменьшение размерности (PCA). Применяются для сегментации данных и визуализации.\n","\n","3. **Обучение с подкреплением**: Модели обучаются через взаимодействие с окружающей средой, получая награды или штрафы. Применяется в робототехнике и играх. Примеры: Q-обучение, алгоритмы глубокого обучения (DQN).\n","\n","Каждый метод имеет свои преимущества и области применения, и выбор зависит от задачи и доступных данных. \n","\n","Источники: \n","- \"Pattern Recognition and Machine Learning\" (Bishop, 2006)\n","- \"Deep Learning\" (Goodfellow et al., 2016)...\n","   Токены: 359 (in: 84, out: 275)\n","   Стоимость: $0.0002\n","\n","  - Модель: Claude-3 Haiku\n","   ────────────────────────────────────────\n","   Ответ:\n","   Вот краткий обзор основных методов машинного обучения в пределах 300 токенов:\n","\n","Основные методы машинного обучения:\n","1) Supervised Learning (обучение с учителем): Regression, Classification.\n","2) Unsupervised Learning (обучение без учителя): Clustering, Dimensionality Reduction.\n","3) Reinforcement Learning (обучение с подкреплением): Q-Learning, Deep Q-Networks.\n","4) Deep Learning: Feedforward Neural Networks, Convolutional Neural Networks, Recurrent Neural Networks.\n","5) Ensemble Methods: Bagging, Boosting, Random Forests.\n","\n","Каждый из этих методов имеет свои особенности, области применения и алгоритмы. Выбор подходящего метода зависит от конкретной задачи и доступных данных....\n","   Токены: 344 (in: 121, out: 223)\n","   Стоимость: $0.0003\n","\n","  - Модель: Llama-3 8B Instruct\n","   ────────────────────────────────────────\n","   Ответ:\n","   Я расскажу о основных методах машинного обучения, анализируя ключевые понятия и категории.\n","\n","**Классификация методов машинного обучения**\n","\n","Машинное обучение можно разделить на три основные категории: ** supervised learning** (обучение с учителем), **unsupervised learning** (обучение без учителя) и **reinforcement learning** (обучение поощрениями).\n","\n","**1. Обучение с учителем (Supervised Learning)**\n","\n","*   **Линейная регрессия**: установка линейного уравнения для предсказания continuous значения.\n","*   **Классификация**: классификация данных в категории (бинарная, многоклассовая).\n","*   **Decision Trees**: деревья принятия решений для классификации и регрессии.\n","\n","**2. Обучение без учителя (Unsupervised Learning)**\n","\n","*   **Кластеризация**: группировка данных по подобным характеристикам.\n","*   **Анализ главных компонентов**: сворачивание данных в меньшее количество переменных.\n","*   **Счёт разнообразия**: оценка разнообразия в данных.\n","\n","**3. Обучение поощрениями (Reinforcement Learning)**\n","\n","*   **Q-обучение**:...\n","   Токены: 408 (in: 108, out: 300)\n","   Стоимость: $0.0\n","\n","Статистика использования:\n","   GPT-4o-mini:\n","     Запросов: 1\n","     Токенов: 359\n","     Стоимость: $0.0002\n","   Claude-3 Haiku:\n","     Запросов: 1\n","     Токенов: 344\n","     Стоимость: $0.0003\n","   Llama-3 8B Instruct:\n","     Запросов: 1\n","     Токенов: 408\n","     Стоимость: $0.0\n","\n","   Общая стоимость всех запросов: $0.0005\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"njxIuEiSpzSl"},"execution_count":null,"outputs":[]}]}